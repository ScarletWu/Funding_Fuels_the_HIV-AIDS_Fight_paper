---
title: " "
author: Ruoxian Wu
thanks: "Code and data are available at: https://github.com/ScarletWu/Funding_Fuels_the_HIV-AIDS_Fight.git. Replication on Social Science Reproduction platform is available at: https://www.socialsciencereproduction.org/reproductions/1783/"
date: "April 2, 2024"
date-format: long
abstract: " "
format: pdf
toc: true
number-sections: true
bibliography: references.bib
---


# Introduction

Public health funding plays a crucial role in optimizing public health outcomes. To understand the impact of federal funding on HIV/AIDS healthcare, Marcus Dillender's paper "Evidence and Lessons on the Health Impacts of Public Health Funding from the Fight against HIV/AIDS" (2023) assesses the efficacy of Title I funding of the Ryan White Comprehensive AIDS Resources Emergency (CARE) Act [@Dillender2023]. By examining its impact on HIV/AIDS-related mortality and incidence rates, the paper reveals the impact of public funding. 

In this paper, I aim to replicate Dillender's research using available public data and direct my attention to the non-mortality outcomes of the Ryan White CARE Act's Title I funding. I examine its influence on the diagnosis and prevalence rates of HIV/AIDS. It offers a unique perspective on HIV/AIDS-affected populations and potential public health interventions for enhancing their quality of life. Based on Dillender's methodology, I employ difference-in-differences and regression discontinuity designs to examine the sensitivity of the findings to different analyses. As a result of this reanalysis, the original study's results are validated and a dialogue on how to interpret public health data regarding policy impact assessments is stimulated.

This critical replication explores the complex issues surrounding public health funding. I analyze the interplay of financial inputs, health outcomes, and the socio-economic fabrics they weave into. I hope that this critical replication encourages a more nuanced approach to future research in public health finance and policy-making. Throughout this investigation, I keep an eye on societal, economic, and systemic factors that influence public health and how federal funding operates within that ecosystem.

# Data
My reproduction used the programming language R [@r], the analysis used the following packages: Haven[@rHaven], Dplyr [@rDplyr], Ggplot2 [@rGgplot2], Readr [@rReadr], Here [@rHere], Janitor [@rJanitor], KableExtra [@rKableExtra], Knitr [@rKnitr], Tidyverse [@rTidyverse].My reproduction seeks to address two findings written in the original paper.

## Source
The paper used for replication is from American Economic Association, American Economic Review. The replication package is downloaded from Evidence and Lessons on the Health Impacts of Public Health Funding from the Fight against HIV/AIDS, under Additional Materials. 

## Variables
In progress

# Results

```{r}
# Load necessary libraries
library(dplyr)
library(glmnet)

# Assume data has already been loaded and preprocessed correctly
# Summary of response variables to check variability
lapply(response_vars, function(var) {
  cat("Summary for", var, ":\n")
  print(summary(data_filtered[[var]]))
  cat("Number of unique values in", var, ":", length(unique(data_filtered[[var]])), "\n\n")
})

# Check the number of rows in the filtered data
cat("Number of rows in data_filtered:", nrow(data_filtered), "\n")

# If data filtering is causing issues, adjust it here and re-check
data_filtered <- data %>%
  filter(complete.cases(cases_per_100000, deaths_per_100000, red_zone, orange_zone, geo_state, fem_resp_age)) %>%
  filter(!is.na(ind_fem_depression_change) & 
         !is.na(ind_fem_tired_change) &
         !is.na(ind_fem_worried_change) & 
         !is.na(ind_fem_safety_change) &
         final_status %in% c("Fully complete", "Partially complete"))

# Repeat the variability check after re-filtering
lapply(response_vars, function(var) {
  cat("Rechecked Summary for", var, ":\n")
  print(summary(data_filtered[[var]]))
  cat("Rechecked Number of unique values in", var, ":", length(unique(data_filtered[[var]])), "\n\n")
})
```

```{r}
library(plm)
library(lmtest)
library(sandwich)
library(stargazer)
library(glmnet)
library(dplyr)
library(readstata13)

# Set file paths
data_path <- "/cloud/project/data/raw_data/"
data_file <- paste0(data_path, "covid_gender_data.dta")

data <- read_dta(data_file)
```

```{r}
# Convert appropriate columns to factors (if they are not already)
data$geo_state <- as.factor(data$geo_state)
data$fem_resp_age <- as.factor(data$fem_resp_age)
data$geo_district <- as.factor(data$geo_district) # Ensure geo_district is a factor for clustering

data_filtered <- data %>% 
  filter(complete.cases(cases_per_100000, deaths_per_100000, red_zone, orange_zone, geo_state, fem_resp_age)) %>%
  filter(!is.na(ind_fem_depression_change) & 
           !is.na(ind_fem_tired_change) &
           !is.na(ind_fem_worried_change) & 
           !is.na(ind_fem_safety_change) &
           final_status %in% c("Fully complete", "Partially complete"))

# Define response and predictor variables
response_vars <- c("ind_fem_depression_change", "ind_fem_tired_change", 
                   "ind_fem_worried_change", "ind_fem_safety_change", 
                   "mental_index_change")
predictors <- c("dist_prop_covid_zone", "red_zone", "orange_zone", 
                "cases_per_100000", "deaths_per_100000", "tran_inc_normal", 
                "asset_index", "ind_fem_resp_edu")

# Generate dummy variables for categorical predictors
dummies <- model.matrix(~ geo_state + fem_resp_age - 1, data = data_filtered)

# Combine the dummies and other predictors
x <- cbind(dummies, data_filtered[, predictors])

# Convert to a matrix for glmnet
x_matrix <- as.matrix(x)
```

```{r}
# Initialize a list to store models
final_models <- list()

# Loop through response variables
for (resp_var in response_vars) {
  y <- data_filtered[[resp_var]]
  cv_fit <- cv.glmnet(x_matrix, y, alpha = 1)
  best_lambda <- cv_fit$lambda.min
  lasso_fit <- glmnet(x_matrix, y, alpha = 1, lambda = best_lambda)
  lasso_coefs <- coef(lasso_fit, s = "lambda.min")
  active_vars <- rownames(lasso_coefs)[lasso_coefs[, 1] != 0]
  active_vars <- active_vars[active_vars != "(Intercept)"]
  final_formula <- as.formula(paste(resp_var, "~", paste(active_vars, collapse = " + ")))
  final_model <- lm(final_formula, data = data_filtered)
  robust_se <- vcovHC(final_model, type = "HC1", cluster = "geo_district")
  final_models[[resp_var]] <- list(model = final_model, robust_se = robust_se)
}


```
# Initialize a list to store models
final_models <- list()

# Loop through response variables
for (resp_var in response_vars) {
  y <- data_filtered[[resp_var]]
  set.seed(123) 
  cv_fit <- cv.glmnet(x_matrix, y, alpha = 1)
  best_lambda <- cv_fit$lambda.min
  lasso_fit <- glmnet(x_matrix, y, alpha = 1, lambda = best_lambda)
  lasso_coefs <- coef(lasso_fit, s = "lambda.min")
  active_vars <- rownames(lasso_coefs)[lasso_coefs[, 1] != 0]
  active_vars <- active_vars[active_vars != "(Intercept)"]
  active_predictors <- x_matrix[, active_vars, drop = FALSE]
  final_formula <- as.formula(paste(resp_var, "~", paste(active_vars, collapse = " + ")))
  
  # Fit the final linear model with robust standard errors
  final_model <- plm(final_formula, data = data_filtered, model = "pooling")
  robust_se <- vcovHC(final_model, type = "HC1", cluster = "group")
  
stargazer::stargazer(
  final_models$ind_fem_depression_change$model,
  final_models$ind_fem_tired_change$model,
  final_models$ind_fem_worried_change$model,
  final_models$ind_fem_safety_change$model,
  final_models$mental_index_change$model,
  type = "text",  # Use "html" or "latex" for different formats suitable for web or LaTeX
  title = "Relationship between Containment and Female Well-being",
  out = "table1.txt",  # Saves the output to a text file
  se = list(final_models$ind_fem_depression_change$robust_se,
            final_models$ind_fem_tired_change$robust_se,
            final_models$ind_fem_worried_change$robust_se,
            final_models$ind_fem_safety_change$robust_se,
            final_models$mental_index_change$robust_se), # Use robust standard errors
  covariate.labels = c("Containment", "Past Containment Controls", "State FE", "Age FE", "Lasso Controls", "Case and Death Controls"),
  omit.stat = c("LL", "ser", "f"), # Exclude some statistics you might not need
  no.space = TRUE, # Reduce space between columns
  column.labels = c("More Depressed", "More Exhausted", "More Anxious", "MH Index", "Less Safe"),
  single.row = TRUE # All info in one row for each model
)


  
```

# Discussion
In progress

# Reference